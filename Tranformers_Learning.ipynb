{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch            # for normal utility functions like random etc..\n",
        "import torch.nn as nn   # for neural network related functions, ex: nn.Layer, nn.Module etc..\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import requests\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "Aquwteb9MZaV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'embedding_dim' : 1000,\n",
        "    'model_context_length' : 20,\n",
        "    'q_k_dim' : 600,\n",
        "    'num_heads' : 8,\n",
        "    'ff_intermediate_dim':4000,\n",
        "    'drop_out_prob' : 0.5,\n",
        "    'n_encoders':2,\n",
        "    'n_decoders':2,\n",
        "}\n",
        "config['value_dim'] = config['embedding_dim']//config['num_heads']"
      ],
      "metadata": {
        "id": "tpFGjoEpMZda"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlsS1NWyskks",
        "outputId": "3bec5694-d3d2-456c-bda8-d7b3be125a6f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'embedding_dim': 768,\n",
              " 'model_context_length': 20,\n",
              " 'q_k_dim': 500,\n",
              " 'num_heads': 8,\n",
              " 'ff_intermediate_dim': 4000,\n",
              " 'drop_out_prob': 0.5,\n",
              " 'n_encoders': 2,\n",
              " 'n_decoders': 2,\n",
              " 'value_dim': 96}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Prep. [ ref : #https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare_char/prepare.py ]"
      ],
      "metadata": {
        "id": "cquC0Sj8vAHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L37W9ef8uy0A",
        "outputId": "33d08b34-f089-4632-abcf-8515756ff602"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-15 10:19:33--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-02-15 10:19:33 (20.0 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r') as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "uRzLjCeHuy25"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('length of data : ', len(data))\n",
        "vocab_size = len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ352qIVuy5P",
        "outputId": "fea83db3-efb7-46ac-d61a-03565a3bee71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of data :  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" unique set of characters \", set(data))\n",
        "chars = set(data)\n",
        "print(len(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcDhn8QVuy7r",
        "outputId": "b0e27b03-8619-492b-f9f5-8cb0c89eac7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " unique set of characters  {'r', 'A', \"'\", 'g', 'q', 'j', 'M', 'o', 'y', 'K', 'D', 'G', 'H', 'E', 'Q', 'c', 'Y', 't', 'b', 'x', 'C', 'u', 'F', 'd', ';', 'N', 'p', 'f', 'X', 'a', 's', 'h', 'l', '3', 'n', 'O', '&', '?', 'z', 'w', 'U', 'T', ',', 'i', 'Z', 'S', 'B', 'I', 'J', '$', ':', 'k', 'P', ' ', 'v', 'W', '-', 'R', '.', 'L', 'V', '!', 'm', '\\n', 'e'}\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config['vocab_size'] = len(chars)"
      ],
      "metadata": {
        "id": "UR0pif0A8dpv"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "ctoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itoc = { i:ch for i,ch in enumerate(chars) }"
      ],
      "metadata": {
        "id": "i3gr0Odav1He"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ctoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dam_bvgFv1KF",
        "outputId": "001cbb1d-b0ef-4c32-e4c7-4cce7be69d70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'r': 0, 'A': 1, \"'\": 2, 'g': 3, 'q': 4, 'j': 5, 'M': 6, 'o': 7, 'y': 8, 'K': 9, 'D': 10, 'G': 11, 'H': 12, 'E': 13, 'Q': 14, 'c': 15, 'Y': 16, 't': 17, 'b': 18, 'x': 19, 'C': 20, 'u': 21, 'F': 22, 'd': 23, ';': 24, 'N': 25, 'p': 26, 'f': 27, 'X': 28, 'a': 29, 's': 30, 'h': 31, 'l': 32, '3': 33, 'n': 34, 'O': 35, '&': 36, '?': 37, 'z': 38, 'w': 39, 'U': 40, 'T': 41, ',': 42, 'i': 43, 'Z': 44, 'S': 45, 'B': 46, 'I': 47, 'J': 48, '$': 49, ':': 50, 'k': 51, 'P': 52, ' ': 53, 'v': 54, 'W': 55, '-': 56, 'R': 57, '.': 58, 'L': 59, 'V': 60, '!': 61, 'm': 62, '\\n': 63, 'e': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting integers to string and string to integers\n",
        "def encode(s):\n",
        "    return [ctoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "def decode(l):\n",
        "    return ''.join([itoc[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "g2jUQa9Av1Ms"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"hello there\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs7TZ0uwwmNt",
        "outputId": "508db3e4-6a21-4d39-8ae4-55f68cb437e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31, 64, 32, 32, 7, 53, 17, 31, 64, 0, 64]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(encode(\"hello there\"))     # decoding the encoded values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "twFxQ2O87e43",
        "outputId": "2638a76a-4cbd-4447-fd8b-037e80891b4e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello there'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qBvun_ivVIky",
        "outputId": "8422f615-f3f5-4de3-8eb1-dbba0bd27024"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'r'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "\n",
        "n = len(data)\n",
        "train_data = data[:int(n*0.9)]\n",
        "val_data = data[int(n*0.9):]"
      ],
      "metadata": {
        "id": "t8SXkOnUwmQj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode both to integers\n",
        "train_ids = encode(train_data)\n",
        "val_ids = encode(val_data)\n",
        "print(f\"train has {len(train_ids):,} tokens\")\n",
        "print(f\"val has {len(val_ids):,} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aotQTmECwmTA",
        "outputId": "5850e183-ad4b-4faf-dab4-28fb56915735"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for returning the batch of base data\n",
        "def batch_data(batch_size, context_length, context = 'train'):\n",
        "  data = val_ids if context=='test' else train_ids\n",
        "  indices = torch.randint(low = 0, high=len(data) - context_length, size= (batch_size,))\n",
        "  x = torch.stack([torch.tensor(data[index:index+context_length]) for index in indices])\n",
        "  y = torch.stack([torch.tensor(data[index+1:index+1+context_length]) for index in indices])\n",
        "  return x, y\n",
        "\n",
        "\n",
        "# # function for visualizing the data how transformer processes it\n",
        "\n",
        "# def prepare_data(batch_size, x,y):\n",
        "#     train_x, train_y = [],[]\n",
        "\n",
        "#     for batch_ind in range(batch_size):\n",
        "#       train_x=[x[batch_ind,:i+1] for i in range(x.shape[1])]\n",
        "#       train_y=[y[batch_ind, i] for i in range(y.shape[1])]\n",
        "#       train_x = pad_sequence(train_x, batch_first=True, padding_value=-1)\n",
        "#       train_y = torch.tensor(train_y)\n",
        "#     return train_x, train_y\n",
        "\n",
        "def get_data(context, batch_size=8):\n",
        "  batch_size, context_length = batch_size, config['model_context_length']\n",
        "  x, y = batch_data(batch_size, context_length, context=context)\n",
        "  # train_x, train_y = prepare_data(batch_size,x,y)\n",
        "  return x, y\n",
        "\n",
        "\n",
        "\n",
        "x,y = get_data('train')"
      ],
      "metadata": {
        "id": "OxFekwDUxqnj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMGEDy82HHuK",
        "outputId": "07224160-d9f3-4062-d52d-8493a183eb43"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[64, 17, 53, 18,  0, 64, 29, 30, 17, 58],\n",
              "        [64, 53, 27,  0, 64, 30, 31, 64, 30, 17],\n",
              "        [34, 53, 29, 34, 53, 29, 30, 30,  2, 30],\n",
              "        [ 3, 64, 53, 30, 64, 32, 23,  7, 62, 53],\n",
              "        [64, 34, 42, 53, 29, 53, 31, 29, 26, 32],\n",
              "        [31, 29, 17, 53, 39, 64, 53, 23, 43, 23],\n",
              "        [63, 46, 64, 15, 29, 21, 30, 64, 53, 47],\n",
              "        [64, 30, 53, 32,  7, 34,  3, 53, 29,  3]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text embedding\n",
        "\n",
        "class embedding(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(embedding, self).__init__()\n",
        "    self.embedding_layer = nn.Embedding(num_embeddings = config['vocab_size'], embedding_dim = config['embedding_dim'])\n",
        "    self.positional_embedding = nn.Embedding(num_embeddings = config['model_context_length'], embedding_dim = config['embedding_dim'])\n",
        "\n",
        "  def forward(self, encodings):\n",
        "    embeddings = self.embedding_layer(encodings)\n",
        "\n",
        "    # positional embeddings\n",
        "    positional_encodings = torch.arange(encodings.size(1)).unsqueeze(0)\n",
        "    positionals_embed = self.positional_embedding(positional_encodings)\n",
        "\n",
        "    return embeddings + positionals_embed                  # returns (*encodings.shape,  config.embedding_dim), sum is happening after broadcast"
      ],
      "metadata": {
        "id": "cxNrm-RpyZro"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed = embedding()\n",
        "# inp = torch.randint( high=9, size=(1,13))\n",
        "# print(inp)\n",
        "# embed.positional_embedding(inp)"
      ],
      "metadata": {
        "id": "hSAyKyFCFlW3"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config['model_context_length']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfaPIdf1GP4g",
        "outputId": "6ab0018b-da0d-4497-fb10-35b6f7149dc6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eF4ZM1u7GP7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Self_Attention(nn.Module):\n",
        "  def __init__(self, mask=False):\n",
        "    super(Self_Attention, self).__init__()\n",
        "    self.query = nn.Linear(config['embedding_dim'], config['q_k_dim'])\n",
        "    self.key = nn.Linear(config['embedding_dim'], config['q_k_dim'])\n",
        "    self.value = nn.Linear(config['embedding_dim'], config['value_dim'])\n",
        "    self.mask = mask\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "\n",
        "    if not isinstance(inputs, list):                                             # for cross attention send input as [query, key, value]\n",
        "      inputs = [inputs]*3\n",
        "\n",
        "    queries = self.query(inputs[0])\n",
        "    keys = self.key(inputs[1])\n",
        "    values = self.value(inputs[2])\n",
        "    keys = torch.transpose(keys,1,2)\n",
        "    attentions = torch.matmul(queries, keys)*(torch.sqrt(torch.tensor(keys.size(1))))**-1\n",
        "\n",
        "    # print(\"are we doing masking ? \", self.mask)\n",
        "\n",
        "    if self.mask:\n",
        "      # print('masking the attentions for decoder')\n",
        "      attentions = torch.tril(attentions)\n",
        "      attentions = attentions.masked_fill(attentions==0, -float('inf'))\n",
        "\n",
        "    attentions = self.softmax(attentions)\n",
        "\n",
        "    return attentions, torch.matmul(attentions, values)\n"
      ],
      "metadata": {
        "id": "zmu4YBJogU7F"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed = embedding()\n",
        "# obj = Self_Attention()\n",
        "# encodings = torch.randint(0, config['vocab_size'], (2, 10))\n",
        "# embeddings = embed(encodings)\n",
        "# attentions, res = obj(embeddings)\n",
        "# res.size()"
      ],
      "metadata": {
        "id": "5WPmff7vgVB4"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class multi_head_attention(nn.Module):\n",
        "  def __init__(self, mask=False):\n",
        "    super(multi_head_attention, self).__init__()\n",
        "    self.attentions = [Self_Attention(mask) for _ in range(config['num_heads'])]\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    self_attention_heads = [self_attention(inputs)[1] for self_attention in self.attentions]      # passing input to each head separately\n",
        "    return torch.cat(self_attention_heads, dim=-1)"
      ],
      "metadata": {
        "id": "n5JEMAORx2po"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed = embedding()\n",
        "# obj = multi_head_attention()\n",
        "\n",
        "# encodings = torch.randint(0, config['vocab_size'], (2, 10))\n",
        "# embeddings = embed(encodings)\n",
        "# # attentions, res = obj(embeddings)\n",
        "# res = obj(embeddings)\n",
        "# res.size()"
      ],
      "metadata": {
        "id": "cPvnwmJtx2s0"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class feed_forward(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(feed_forward, self).__init__()\n",
        "    self.FF_1 = nn.Linear(config['embedding_dim'], config['ff_intermediate_dim'])\n",
        "    self.FF_2 = nn.Linear(config['ff_intermediate_dim'], config['embedding_dim'])\n",
        "    self.gelu = nn.GELU()\n",
        "    self.dropout = nn.Dropout(config['drop_out_prob'])\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    FF1_outputs = self.FF_1(inputs)\n",
        "    FF1_outputs_nonlinear = self.gelu(FF1_outputs)\n",
        "    FF2_outputs = self.FF_2(FF1_outputs_nonlinear)\n",
        "    forward_out = self.dropout(FF2_outputs)\n",
        "    return forward_out"
      ],
      "metadata": {
        "id": "6gcnPJm3Yo7h"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = embedding()\n",
        "obj = multi_head_attention()\n",
        "ff = feed_forward()\n",
        "\n",
        "encodings = torch.randint(0, config['vocab_size'], (2, 10))\n",
        "embeddings = embed(encodings)\n",
        "# attentions, res = obj(embeddings)\n",
        "res = obj(embeddings)\n",
        "ff(res).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPXkkHuAYo_F",
        "outputId": "a53c8ab7-7d1b-4a0e-97bb-cc9caafc287b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.MHA = multi_head_attention()\n",
        "    self.ff = feed_forward()\n",
        "    self.layer_norm_1 = nn.LayerNorm(config['embedding_dim'])\n",
        "    self.layer_norm_2 = nn.LayerNorm(config['embedding_dim'])\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    encoder_inputs = self.layer_norm_1(inputs)\n",
        "    Attended_embeds = self.MHA(encoder_inputs) + inputs\n",
        "    ff_res = self.ff(self.layer_norm_2(Attended_embeds))+Attended_embeds\n",
        "    return ff_res"
      ],
      "metadata": {
        "id": "xgcw5j9-5q7H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed = embedding()\n",
        "# encoder = Encoder()\n",
        "# # obj = multi_head_attention()\n",
        "# # ff = feed_forward()\n",
        "\n",
        "# encodings = torch.randint(0, config['vocab_size'], (2, 10))\n",
        "# embeddings = embed(encodings)\n",
        "# # attentions, res = obj(embeddings)\n",
        "# res = encoder(embeddings)\n",
        "# res.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln45KGl8T93z",
        "outputId": "5437d847-b6ea-40bc-e3a9-a4844f9402af"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VvxatQRZT-In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "KRFMFRg_qJJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.masked_MHA = multi_head_attention(mask=True)\n",
        "    self.MHA = multi_head_attention()\n",
        "    self.ff = feed_forward()\n",
        "    self.layer_norm_1 = nn.LayerNorm(config['embedding_dim'])\n",
        "    self.layer_norm_2 = nn.LayerNorm(config['embedding_dim'])\n",
        "    self.layer_norm_3 = nn.LayerNorm(config['embedding_dim'])\n",
        "\n",
        "\n",
        "  def forward(self, encoder_output, decoder_input):\n",
        "    decoder_input_normalized = self.layer_norm_1(decoder_input)\n",
        "    masked_decoder_output = self.masked_MHA(decoder_input_normalized) + decoder_input\n",
        "    masked_decoder_output_normalized = self.layer_norm_2(masked_decoder_output)\n",
        "    cross_attention_output = self.MHA([masked_decoder_output_normalized, encoder_output, encoder_output]) + masked_decoder_output\n",
        "    cross_attention_output_normalized = self.layer_norm_3(cross_attention_output)\n",
        "    ff_output = self.ff(cross_attention_output_normalized)  + cross_attention_output\n",
        "\n",
        "    return ff_output\n"
      ],
      "metadata": {
        "id": "I9XYw80LnjBh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Completer Transformer Architecture"
      ],
      "metadata": {
        "id": "DZrUz17oT1E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, n_encoders, n_decoders):\n",
        "    self.encoders = [Encoder() for _ in range(n_encoders)]\n",
        "    self.decoders = [Decoder() for _ in range(n_decoders)]\n",
        "\n",
        "\n",
        "  def forward(self, encoder_inputs, decoder_inputs):\n",
        "    encoder_outputs = [encoder_inputs := encoder(encoder_inputs) for encoder in self.encoders]\n",
        "    decoder_outputs = [decoder_inputs := decoder(encoder_outputs[-1], decoder_inputs) for decoder in self.decoders]\n",
        "    return decoder_outputs\n"
      ],
      "metadata": {
        "id": "mnwCRUAxnmx7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformers = Transformer(config['n_encoders'], config['n_decoders'])"
      ],
      "metadata": {
        "id": "P0zx4coA_38a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m4tt_-6ByNlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT ( Decoder only Transformer )"
      ],
      "metadata": {
        "id": "e19U0OX1yO3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.layer_norm_1 = nn.LayerNorm(config['embedding_dim'])\n",
        "    self.MHA = multi_head_attention(mask=True)\n",
        "    self.layer_norm_2 = nn.LayerNorm(config['embedding_dim'])\n",
        "    self.ff = feed_forward()\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    inputs_normalized = self.layer_norm_1(inputs)\n",
        "    inputs_attention  = self.MHA(inputs_normalized) + inputs\n",
        "    inputs_attention_normalized = self.layer_norm_2(inputs_attention)\n",
        "    decoder_response = self.ff(inputs_attention_normalized) + inputs_attention\n",
        "\n",
        "    return decoder_response\n"
      ],
      "metadata": {
        "id": "Fzfy0HCtyNn3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "  def __init__(self, n_decoder):\n",
        "    super(GPT, self).__init__()\n",
        "    self.decoders = nn.Sequential(*[Decoder() for _ in range(n_decoder)])\n",
        "    self.linear = nn.Linear(in_features=config['embedding_dim'], out_features=config['vocab_size'])\n",
        "    # self.decoders = nn.Sequential([decoder() for decoder in self.decoders])\n",
        "    self.embed = embedding()\n",
        "    self.loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  # def forward(self, decoder_input, targets):\n",
        "  #   embddings = self.embed(decoder_input)\n",
        "  #   decoders_response = self.decoders(embddings)\n",
        "  #   gpt_predictions = self.linear(decoders_response)\n",
        "  #   # reshaping for Loss function\n",
        "  #   B,T,C = gpt_predictions.shape\n",
        "  #   gpt_predictions = gpt_predictions.view(B*T, C)\n",
        "  #   B,T = targets.shape\n",
        "  #   targets = targets.view(B*T)\n",
        "\n",
        "  #   loss_value = self.loss(gpt_predictions, targets)\n",
        "  #   return gpt_predictions, loss_value\n",
        "\n",
        "\n",
        "  def forward(self, decoder_input, targets=None):\n",
        "      embddings = self.embed(decoder_input)\n",
        "      decoders_response = self.decoders(embddings)\n",
        "      gpt_predictions = self.linear(decoders_response)\n",
        "      # reshaping for Loss function\n",
        "      B,T,C = gpt_predictions.shape\n",
        "      gpt_predictions = gpt_predictions.view(B*T, C)\n",
        "      if targets is not None:\n",
        "        B,T = targets.shape\n",
        "        targets = targets.view(B*T)\n",
        "\n",
        "      if targets is not None:\n",
        "        loss_value = self.loss(gpt_predictions, targets)\n",
        "      else:\n",
        "        loss_value = None\n",
        "      return gpt_predictions, loss_value\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d-NEK6VByNqc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @torch.no_grad()\n",
        "# def estimate_loss():\n",
        "#     out = {}\n",
        "#     model.eval()\n",
        "#     for split in ['train', 'val']:\n",
        "#         losses = torch.zeros(eval_iters)\n",
        "#         for k in range(eval_iters):\n",
        "#             X, Y = get_data(split)\n",
        "#             logits, loss = model(X, Y)\n",
        "#             losses[k] = loss.item()\n",
        "#         out[split] = losses.mean()\n",
        "#     model.train()\n",
        "#     return out"
      ],
      "metadata": {
        "id": "WzhC4AJV7aN1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing to make sure model is processing properly\n",
        "\n",
        "model = GPT(n_decoder=1)\n",
        "\n",
        "total_params = sum(\n",
        "\tparam.numel() for param in model.parameters()\n",
        ")\n",
        "print(\"total model params \", total_params/1e6, \"Million\")\n",
        "\n",
        "\n",
        "xb, yb = get_data('train', batch_size=2)\n",
        "print(xb)\n",
        "print(xb.shape)\n",
        "print(yb.shape)\n",
        "# evaluate the loss\n",
        "logits, loss = model(xb, yb)\n",
        "\n",
        "print(\"any logits with nan ? \" ,logits.isnan().sum())\n",
        "print(\"loss value \", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cEJV8BKyNs9",
        "outputId": "5a6543dc-7064-4b49-8271-12c8d84744c9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total model params  8.159065 Million\n",
            "tensor([[62,  7,  0, 17, 29, 32, 30, 53, 17, 31, 29, 17, 53, 27, 29, 32, 32, 53,\n",
            "         18, 29],\n",
            "        [32, 23, 53, 62, 29, 34, 53, 23,  7, 64, 30, 53, 39, 31, 64, 34, 53, 17,\n",
            "         31, 64]])\n",
            "torch.Size([2, 20])\n",
            "torch.Size([2, 20])\n",
            "any logits with nan ?  tensor(0)\n",
            "loss value  tensor(4.4004, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETZ7-52f2X8D",
        "outputId": "3131cbc5-62da-48b7-dffb-76c32adad7c2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 65])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(model, max_length, sentence_start = None):\n",
        "\n",
        "  if sentence_start is None:\n",
        "    start_token = torch.randint(low=0, high=config['vocab_size'], size=(1,))\n",
        "    start_token = start_token.tolist()\n",
        "  else:\n",
        "    start_token = encode(sentence_start)\n",
        "    start_token = start_token\n",
        "\n",
        "  predicted_sentence = []\n",
        "  print(\"start token \" , start_token)\n",
        "  predicted_sentence.append(decode(start_token))\n",
        "  model.eval()\n",
        "  while len(predicted_sentence)!=max_length:\n",
        "    input = torch.tensor(start_token).unsqueeze(0)\n",
        "    # print(\"input : \", input, \" input shape : \", input.shape)\n",
        "    prediction, loss = model(input)\n",
        "\n",
        "    # print(\"predictions shape : \", prediction.shape)\n",
        "\n",
        "    pred_char_index = np.argmax(prediction[-1,:])\n",
        "    pred_char_index = pred_char_index.tolist()\n",
        "    # print(\"PREDICTED index \" , pred_char_index)\n",
        "\n",
        "    if not len(start_token)<config['model_context_length']:\n",
        "      start_token = start_token[1:]\n",
        "\n",
        "    start_token.append(pred_char_index)\n",
        "    predicted_char = decode([pred_char_index])\n",
        "    predicted_sentence.append(predicted_char)\n",
        "  model.train()\n",
        "\n",
        "  print(\"\".join(predicted_sentence))\n"
      ],
      "metadata": {
        "id": "Gfnf8J0HxkJn"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 100, sentence_start=\"the\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S4dudOuxvxM",
        "outputId": "bed89239-13af-4a52-a554-06429faf9e2a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start token  [17, 31, 64]\n",
            "the,!:oK3.!yQnEq hQZr:::fw.!:fw.!::fZK3LLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val = torch.randint(high=10, size=(3,))\n",
        "print(val)\n",
        "print(val.tolist())\n",
        "print(val.unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ1ysamoxv6K",
        "outputId": "032a6f1f-7867-4c20-c002-cc73ff59de61"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 4, 8])\n",
            "[5, 4, 8]\n",
            "tensor([[5, 4, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config['max_iters'] = 1000\n",
        "config['eval_interval'] = 10\n",
        "config['eval_iters']=5"
      ],
      "metadata": {
        "id": "ReqK0AZquyNl"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zns9rOZxs0R",
        "outputId": "b78cfb92-b408-4016-de3a-12c4a48e8943"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'embedding_dim': 1000,\n",
              " 'model_context_length': 20,\n",
              " 'q_k_dim': 600,\n",
              " 'num_heads': 8,\n",
              " 'ff_intermediate_dim': 4000,\n",
              " 'drop_out_prob': 0.5,\n",
              " 'n_encoders': 2,\n",
              " 'n_decoders': 2,\n",
              " 'value_dim': 125,\n",
              " 'vocab_size': 65,\n",
              " 'max_iters': 1000,\n",
              " 'eval_interval': 10,\n",
              " 'eval_iters': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = config['max_iters']\n",
        "eval_interval = config['eval_interval']\n",
        "eval_iters = config['eval_iters']\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# initialing the model with #decoder blocks\n",
        "model = GPT(n_decoder=8)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_params = sum(\n",
        "\tparam.numel() for param in model.parameters()\n",
        ")\n",
        "print(\"total model params \", total_params/1e6, \"Million\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_data(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        predict(model, max_length=100)\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_data('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xJxl85jIsEt4",
        "outputId": "2211625b-6057-4162-aa7b-9eaced8b8116"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total model params  64.222065 Million\n",
            "step 0: train loss 4.5936, val loss 4.6434\n",
            "start token  [26]\n",
            "pgaPSbCE;3??QQvvLa?Q,J??????????????????????????????????????????????????????????????????????????????\n",
            "step 10: train loss 5.6975, val loss 5.7208\n",
            "start token  [53]\n",
            " paldshaveasayiffovisatoryyyyyyyyoryyyy:\n",
            "Hayy:\n",
            "Hayyyyyyyyyyyyyy:\n",
            "HHay:\n",
            "Hayyyyyyyyyyyyyyy:\n",
            "Hay:\n",
            "Hayyy\n",
            "step 20: train loss 4.1381, val loss 3.9956\n",
            "start token  [7]\n",
            "o mow w w we h th\n",
            "T rerererererererererer co co co co co atrererererererererer co co co co co atrere\n",
            "step 30: train loss 3.4210, val loss 3.3728\n",
            "start token  [37]\n",
            "? h m moror h s  mollllllllllllld howowis thous hous hous ce hous hous hous ce hous hous hous ce hou\n",
            "step 40: train loss 3.4263, val loss 3.5400\n",
            "start token  [8]\n",
            "youse, feffreereeathase, wise, , ase, wise, ase, ase, ase, ase, ase, ase, ase, ase, ase, ase, ase, a\n",
            "step 50: train loss 3.3630, val loss 3.3791\n",
            "start token  [17]\n",
            "ts ar ararararar, as is arararararararararararararararararararararararararararararararararararararar\n",
            "step 60: train loss 3.1388, val loss 3.1408\n",
            "start token  [52]\n",
            "Pour toutoustour totor tor tofr tofr tofr tofr tofr tofr tofr tofr tofr tofr tofr tofr tofr tofr tof\n",
            "step 70: train loss 3.0112, val loss 3.1212\n",
            "start token  [9]\n",
            "KHENTHETheathe athe the the the woure wore wore the the the the the the the the the the the the the \n",
            "step 80: train loss 3.2653, val loss 3.3358\n",
            "start token  [64]\n",
            "erourerervicerverourougougowowowourererowowourererererougowiougougougourerererererourerererougougoug\n",
            "step 90: train loss 2.7926, val loss 3.0710\n",
            "start token  [17]\n",
            "t t t t t the t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
            "step 100: train loss 2.8134, val loss 2.8752\n",
            "start token  [63]\n",
            "\n",
            "Yonounour bunoulllllllllle thate te te te thalllllllllle thate te te te thalllllllllle thate te te \n",
            "step 110: train loss 2.8245, val loss 2.8420\n",
            "start token  [50]\n",
            ": hen toullle at are the the the the the the the the the the the the the the the the the the the the\n",
            "step 120: train loss 3.0096, val loss 2.8540\n",
            "start token  [38]\n",
            "zand t the me tothange me me me me me me me me me me me me me me me me me me me me me me me me me me\n",
            "step 130: train loss 2.8607, val loss 2.9453\n",
            "start token  [58]\n",
            ".\n",
            "NENICERICENIIO:\n",
            "A ICENICENICENICENICENICICICICICICICICICICICICICICICICICICICICICICICICICICICICICIC\n",
            "step 140: train loss 2.7920, val loss 2.8888\n",
            "start token  [25]\n",
            "Nall the t me t the the the the the the the the the the the the the the the the the the the the the \n",
            "step 150: train loss 2.9070, val loss 2.8685\n",
            "start token  [5]\n",
            "jen therd benthen berd thentherd thentherd thentherd thentherd thentherd thentherd thentherd thenthe\n",
            "step 160: train loss 2.6511, val loss 2.7475\n",
            "start token  [34]\n",
            "nd thake my hake thand thand thand thand thand thand thand thand thand thand thand thand thand thand\n",
            "step 170: train loss 2.8727, val loss 2.8294\n",
            "start token  [31]\n",
            "hithe athe he he thendound thend thend thend thend thend thend thend thend thend thend thend thend t\n",
            "step 180: train loss 2.8713, val loss 2.8391\n",
            "start token  [23]\n",
            "d,\n",
            "NGBRETENGBENGBREEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "step 190: train loss 2.7997, val loss 2.8097\n",
            "start token  [13]\n",
            "E:\n",
            "Her mererander mer therer ther therer therer ther therer therer ther therer therer ther therer th\n",
            "step 200: train loss 2.8117, val loss 2.6836\n",
            "start token  [21]\n",
            "urend toue thererese thee the the the the thee the the the the thee the the the the thee the the the\n",
            "step 210: train loss 2.7737, val loss 2.7123\n",
            "start token  [56]\n",
            "-e o the te te we tie the the the the the the the the the the the the the the the the the the the th\n",
            "step 220: train loss 2.8558, val loss 2.7699\n",
            "start token  [51]\n",
            "k atheatheat theatheatheatheatheatheatheatheatheatheatheatheatheatheatheatheatheatheatheatheatheathe\n",
            "step 230: train loss 2.7117, val loss 2.6413\n",
            "start token  [40]\n",
            "US:\n",
            "We IORI s me I I thathe the the the the the the the the the the the the the the the the the the \n",
            "step 240: train loss 2.7883, val loss 2.8462\n",
            "start token  [32]\n",
            "ld he the he he hes the the the the the the the the the the the the the the the the the the the the \n",
            "step 250: train loss 2.7299, val loss 2.8148\n",
            "start token  [40]\n",
            "USe me me ar meare me me me me me me me me me me me me me me me me me me me me me me me me me me me \n",
            "step 260: train loss 2.7996, val loss 2.7445\n",
            "start token  [63]\n",
            "\n",
            "Se torore t the tout tout tour t tout t t tout toure t toure t tout tout t toure t t tout tout tout\n",
            "step 270: train loss 2.8230, val loss 2.7623\n",
            "start token  [24]\n",
            ";\n",
            "\n",
            "\n",
            "Se ofof t the he t t tofofof t t the t t the the t t tofofof t t the t t the the t t tofofof t t\n",
            "step 280: train loss 2.6668, val loss 2.7313\n",
            "start token  [38]\n",
            "ze my he there he he the the the the the the the the the the the the the the the the the the the the\n",
            "step 290: train loss 2.7847, val loss 2.7321\n",
            "start token  [54]\n",
            "ve thererengrere the the the the the the the the the the the the the the the the the the the the the\n",
            "step 300: train loss 2.6892, val loss 2.7573\n",
            "start token  [53]\n",
            " gourer mind thind thind thin thind thind thind this thind thind thind this thind thind thind this t\n",
            "step 310: train loss 2.7441, val loss 2.6615\n",
            "start token  [6]\n",
            "Mand thand the thand t t t t t thand thang t t t t t thand t t t t tond t thang t t t t thang t t t \n",
            "step 320: train loss 2.6759, val loss 2.6923\n",
            "start token  [57]\n",
            "RD VICor the ke the pe perere poure pe pe poureres pere pe poure poure poure pere pes pere pere peth\n",
            "step 330: train loss 2.6253, val loss 2.6620\n",
            "start token  [21]\n",
            "ut the athe the the porave poraved porave porave porave porave porave porave porave porave porave po\n",
            "step 340: train loss 2.6562, val loss 2.6579\n",
            "start token  [14]\n",
            "QUS:\n",
            "And t the t t t t t t t t toulouloule t t t t t t t t toulouloule t t t t t t t t toulouloule t\n",
            "step 350: train loss 2.6170, val loss 2.7243\n",
            "start token  [28]\n",
            "X thind the the the t the t ind the the t the the t the ind t the the t the the in the the t the the\n",
            "step 360: train loss 2.6421, val loss 2.6219\n",
            "start token  [14]\n",
            "QUS:\n",
            "Whe allllld sthe t t t t t t toure t t t t t t t toure t t t t t t t toure t t t t t t t toure \n",
            "step 370: train loss 2.6915, val loss 2.6212\n",
            "start token  [18]\n",
            "be the he s he he the the the the the the the the the the the the the the the the the the the the th\n",
            "step 380: train loss 2.6685, val loss 2.6163\n",
            "start token  [25]\n",
            "NE:\n",
            "What I a ar I anourind t t t the the that t the t the t the the the t the t that the t the t t t\n",
            "step 390: train loss 2.7327, val loss 2.6017\n",
            "start token  [17]\n",
            "the merend that sthesthe the sthe sthe f fathesthesthesthe sthe sthe sthe sthe sthe sthe sthe sthe s\n",
            "step 400: train loss 2.5239, val loss 2.5881\n",
            "start token  [2]\n",
            "'s ther to the tour ther ther ther ther ther ther ther ther ther ther ther ther ther ther ther ther \n",
            "step 410: train loss 2.6295, val loss 2.6257\n",
            "start token  [29]\n",
            "and inor thathind that t t t hathat that t t t that that that t t t that that that t t t that that t\n",
            "step 420: train loss 2.6511, val loss 2.6456\n",
            "start token  [61]\n",
            "!\n",
            "\n",
            "IUSIUS:\n",
            "MENIUS:\n",
            "Wan than than than the the the the therere the the the than the the the the there\n",
            "step 430: train loss 2.7037, val loss 2.7284\n",
            "start token  [57]\n",
            "RGARET:\n",
            "The me he therererererererererererererererererererererererererererererererererererererererer\n",
            "step 440: train loss 2.6186, val loss 2.5772\n",
            "start token  [0]\n",
            "rove hand thath the that that thathat t that that thathat t that that thathat t that that thathat t \n",
            "step 450: train loss 2.6365, val loss 2.6125\n",
            "start token  [16]\n",
            "Youthe be arind be wind and and and and and and and and and and and and and and and and and and and \n",
            "step 460: train loss 2.6343, val loss 2.5687\n",
            "start token  [34]\n",
            "nd are the the or thes s s sthes s theares t t thes s s theares s thes s thes s thes thes t thes the\n",
            "step 470: train loss 2.6009, val loss 2.5494\n",
            "start token  [38]\n",
            "ze southe the the the t t the the the the t the the the t the the the t the the the t the the the t \n",
            "step 480: train loss 2.5752, val loss 2.5986\n",
            "start token  [13]\n",
            "E:\n",
            "Halll be and and therererere this this this therererererer this this this therererererer this thi\n",
            "step 490: train loss 2.6419, val loss 2.6802\n",
            "start token  [27]\n",
            "fore ther heare whe ther therer ther therere there ther therer there therer there therer there there\n",
            "step 500: train loss 2.5993, val loss 2.6223\n",
            "start token  [42]\n",
            ", and the the the than than than than than than than than than than than than than than than than th\n",
            "step 510: train loss 2.6515, val loss 2.6366\n",
            "start token  [15]\n",
            "ce domy the he he he t t t the the the t t t t the the the t t t t the the the t t t t the the the t\n",
            "step 520: train loss 2.4998, val loss 2.6074\n",
            "start token  [23]\n",
            "d the the the the he the the the the the the the the the the the the the the the the the the the the\n",
            "step 530: train loss 2.6225, val loss 2.5884\n",
            "start token  [11]\n",
            "GARD:\n",
            "Whand whor I wor wor br blllllllor br bre bre brenorenor br wor blllllor br br brenor brenor b\n",
            "step 540: train loss 2.5080, val loss 2.7561\n",
            "start token  [7]\n",
            "our the he the the s the the the the the the the the the the the the the the the the the the the the\n",
            "step 550: train loss 2.6428, val loss 2.6739\n",
            "start token  [3]\n",
            "gerer an and and therere the the the ather athe the the the athe athe the the the athe athe the the \n",
            "step 560: train loss 2.7053, val loss 2.6300\n",
            "start token  [30]\n",
            "s me the tor the the the the the the the the the the the the the the the the the the the the the the\n",
            "step 570: train loss 2.6070, val loss 2.6412\n",
            "start token  [7]\n",
            "on t the the the the the hou hou hou hou the the the he the hou thou hou the he the hou the thou he \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-962ffd83484f>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# evaluate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-056c864ce0d5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_input, targets)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0membddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mdecoders_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mgpt_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoders_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# reshaping for Loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c8a070869871>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minputs_attention\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMHA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_normalized\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minputs_attention_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdecoder_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_attention_normalized\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-fcba5f980480>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mFF1_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFF_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mFF1_outputs_nonlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFF1_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mFF2_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFF_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFF1_outputs_nonlinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sVn37d5tyNvt"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PipqKZDdyNyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_uQwqRQRyN1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cASH3aYQyN4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWvKduTFyN63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJjcJtbXyN9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oE7bY0Oa_4Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G5L_PAzS_4DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = [1, 2, 3, 4, 5, 6]\n",
        "# squared_evens = [square := n ** 2 for n in numbers if (n % 2 == 0)]\n",
        "squared_evens = [n ** 2 for n in numbers if (n % 2 == 0)]\n"
      ],
      "metadata": {
        "id": "bi2aYwssnm22"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 2\n",
        "[x:=x**i for i in list(range(1,5))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsF1sURB-wfA",
        "outputId": "39bfbafe-d254-4ff7-fe6b-4f3ad7766e4d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 64, 16777216]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squared_evens"
      ],
      "metadata": {
        "id": "m_OqnDAz0alG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0490f135-461d-4a03-e85b-abf0d1cb6712"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 16, 36]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squared_evens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5SBrJl577iF",
        "outputId": "d037a706-a951-4477-948b-abe7d62f1875"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 16, 36]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((5*2)+5)**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_pud0VM2mEr",
        "outputId": "976b3f14-b3ab-48f0-8196-46a4d380385b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "225"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iFBZ8Hw121w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func1(x):\n",
        "    return x * 2\n",
        "\n",
        "def func2(x):\n",
        "    return x + 5\n",
        "\n",
        "def func3(x):\n",
        "    return x ** 2\n",
        "\n",
        "\n",
        "functions_list = [func1, func2, func3]\n",
        "\n",
        "input_value = 5  # The initial input value\n",
        "\n",
        "result = [input_value := func(input_value) for func in functions_list]\n",
        "print(result[-1])  # The final output after chaining all functions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc30Qfik2mIL",
        "outputId": "892594c2-5cb2-47d7-ea07-545f6c663d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXMyUTfG3Sq-",
        "outputId": "21fd9656-991f-4bfb-c812-28c3d099d228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 15, 225]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class masked_head_attention(nn.Module):\n",
        "#     def __init__(self):\n",
        "#       self.query = nn.Linear(config['embedding_dim'], config['q_k_dim'])\n",
        "#       self.key= nn.Linear(config['embedding_dim'], config['q_k_dim'])\n",
        "#       self.value = nn.Linear(config['embedding_dim'], config['value_dim'])\n",
        "\n",
        "#     def forward(self, inputs):\n",
        "#       self.\n"
      ],
      "metadata": {
        "id": "kEKhvT860an9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dim_feedforward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
        "        self.cross_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_feedforward),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim_feedforward, d_model)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        tgt2 = self.self_attention(tgt, tgt, tgt, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout(tgt2)\n",
        "        tgt = self.norm1(tgt)\n",
        "\n",
        "        tgt2 = self.cross_attention(tgt, memory, memory, attn_mask=memory_mask, key_padding_mask=memory_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout(tgt2)\n",
        "        tgt = self.norm2(tgt)\n",
        "\n",
        "        tgt2 = self.feed_forward(tgt)\n",
        "        tgt = tgt + self.dropout(tgt2)\n",
        "        tgt = self.norm3(tgt)\n",
        "\n",
        "        return tgt\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dim_feedforward, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, dim_feedforward, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "        return tgt\n"
      ],
      "metadata": {
        "id": "7xowt6kM0aqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dropout=0.0):\n",
        "        super(MultiheadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "\n",
        "        self.query_linear = nn.Linear(d_model, d_model)\n",
        "        self.key_linear = nn.Linear(d_model, d_model)\n",
        "        self.value_linear = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.output_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n",
        "        batch_size, seq_len, _ = query.size()\n",
        "\n",
        "        query = self.query_linear(query)\n",
        "        key = self.key_linear(key)\n",
        "        value = self.value_linear(value)\n",
        "\n",
        "        query = self._reshape_to_batches(query)\n",
        "        key = self._reshape_to_batches(key)\n",
        "        value = self._reshape_to_batches(value)\n",
        "\n",
        "        # Compute scaled dot-product attention\n",
        "        attention_scores = torch.matmul(query, key.transpose(-2, -1)) / self.head_dim**0.5\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attention_scores += attn_mask.unsqueeze(1)\n",
        "\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context = torch.matmul(attention_probs, value)\n",
        "        context = self._reshape_from_batches(context)\n",
        "        context = self.output_linear(context)\n",
        "\n",
        "        if key_padding_mask is not None:\n",
        "            context = context.masked_fill(key_padding_mask.unsqueeze(-1), 0)\n",
        "\n",
        "        return context\n",
        "\n",
        "    def _reshape_to_batches(self, tensor):\n",
        "        batch_size, seq_len, d_model = tensor.size()\n",
        "        tensor = tensor.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
        "        return tensor.view(batch_size * self.num_heads, seq_len, self.head_dim)\n",
        "\n",
        "    def _reshape_from_batches(self, tensor):\n",
        "        batch_size, seq_len, _ = tensor.size()\n",
        "        tensor = tensor.view(batch_size // self.num_heads, self.num_heads, seq_len, self.head_dim)\n",
        "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
        "        return tensor.view(batch_size // self.num_heads, seq_len, self.d_model)\n"
      ],
      "metadata": {
        "id": "Zno-z9JQ0atb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dznitnbW0awl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh0eSnHe0ay_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4pQMzME0a1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "OYlrEiU-ove4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(1,100,size=(5,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suLYpsiXovhf",
        "outputId": "f47e7aae-afc2-431b-8a82-8fb6fff37ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20,  3, 97,  6, 45],\n",
              "        [29, 82, 72, 18, 97],\n",
              "        [80, 45, 59, 71, 33],\n",
              "        [67, 95, 92,  5, 21],\n",
              "        [22, 13, 43, 69, 40]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tril(torch.randint(1,100, size=(5,5)), diagonal=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWL0Ez1movkV",
        "outputId": "ae3fc0f0-e3db-472b-d1ab-d8ff7944379a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[92,  0,  0,  0,  0],\n",
              "        [96, 87,  0,  0,  0],\n",
              "        [80, 67,  4,  0,  0],\n",
              "        [63, 71, 51, 86,  0],\n",
              "        [24, 17, 74, 47, 46]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = torch.tril(torch.randint(1,100, size=(5,5)), diagonal=0)\n",
        "matrix = matrix.float()\n",
        "matrix.masked_fill(matrix==0, -float('inf'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE01yxU-ovnO",
        "outputId": "77c00da3-c160-45f9-81c4-460ccbc4a937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[55., -inf, -inf, -inf, -inf],\n",
              "        [56., 58., -inf, -inf, -inf],\n",
              "        [ 7., 76., 96., -inf, -inf],\n",
              "        [96., 59., 60., 92., -inf],\n",
              "        [42., 28., 87., 36.,  9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(matrix.masked_fill(matrix==0, -float('inf')), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYa6Qbkpovp2",
        "outputId": "5860e654-4fe8-446b-ee7e-e16cf502422c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [1.1920e-01, 8.8080e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [2.2274e-39, 2.0612e-09, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [9.8201e-01, 8.3796e-17, 2.2778e-16, 1.7986e-02, 0.0000e+00],\n",
              "        [2.8625e-20, 2.3803e-26, 1.0000e+00, 7.0955e-23, 1.3336e-34]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([42., 28., 87., 36.,  9.]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_C7Np7FzQGb",
        "outputId": "51959327-228d-46b8-dfcc-cd04e53a745e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.8625e-20, 2.3803e-26, 1.0000e+00, 7.0955e-23, 1.3336e-34])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([.42, .28, .87, .36,  .9]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-Qdv47izQJb",
        "outputId": "79f70377-c245-4d44-cf1a-7898dc7376c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1668, 0.1450, 0.2616, 0.1571, 0.2695])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yeswapVczQML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.GELU(approximate='tanh')\n",
        "input = torch.randint(100,size=(1,), dtype=torch.float32)\n",
        "m(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMDR4unm5L93",
        "outputId": "cdc138ac-9216-47cb-cfa8-cfae44da6cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([24.])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MxOgKIiD5MBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2,3],[4,5,6]])\n",
        "b = torch.tensor([10,20,30])"
      ],
      "metadata": {
        "id": "9b9m7G6qx2vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma655mBF3f95",
        "outputId": "081407dd-ee8c-4fdc-96ec-f04ca9d83a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[10, 20, 30]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = b.unsqueeze(0)"
      ],
      "metadata": {
        "id": "jMdGoMXf38FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.size())\n",
        "print(b.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Zk8V9_33xU",
        "outputId": "e17eb11b-aea7-4915-ca9c-8fae222dae74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "gtzLwUgc3LoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rX6Cgx213Lrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZafGviPI3Lt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXenEd9Ix2zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHmczNYcgVFH",
        "outputId": "5aa0e8b7-d473-4bb4-89d8-5b79674f9d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vocab_size': 3000,\n",
              " 'embedding_dim': 768,\n",
              " 'model_context_length': 500,\n",
              " 'q_k_dim': 560}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = nn.Linear(config['embedding_dim'], config['q_k_dim'])\n",
        "key = nn.Linear(config['embedding_dim'], config['q_k_dim'])\n",
        "value = nn.Linear(config['embedding_dim'], config['embedding_dim'])\n",
        "\n",
        "\n",
        "print(query.weight.size())\n",
        "print(key.weight.size())\n",
        "print(value.weight.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYCEnGIIgVIh",
        "outputId": "5f23d661-2bb0-4924-cf51-ec00a443ec89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([560, 768])\n",
            "torch.Size([560, 768])\n",
            "torch.Size([768, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_inputs = torch.randn(size=(3,5,768))"
      ],
      "metadata": {
        "id": "jztJLC4vugyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_inputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwLody9XysHo",
        "outputId": "d198269d-76d0-4b74-ddae-cce4531a47f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query(embedded_inputs).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXDFy59Gug01",
        "outputId": "c0433ffa-0cc5-4d6a-a2f5-16da1924f49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5, 560])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = query(embedded_inputs)\n",
        "keys = key(embedded_inputs)\n",
        "values = value(embedded_inputs)\n"
      ],
      "metadata": {
        "id": "iMgl2hBI1YLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(queries.size())\n",
        "keys.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKPnPrzo9uAV",
        "outputId": "c28dfb3b-1d2b-4535-b40c-f1c9924c9c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 5, 560])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5, 560])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = torch.transpose(keys,1,2)"
      ],
      "metadata": {
        "id": "6tzHJokc9-HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErTHPUko-Qr5",
        "outputId": "06e75ccf-802c-4525-9edf-cadd5cc8b998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 560, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(queries, keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxxu9bWjBkj1",
        "outputId": "0d33f4e7-a352-4374-bc0e-f11014db6a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  2.6170,   8.8673,   6.5697,   5.3232,   8.1410],\n",
              "         [ 14.5556,  -4.2279,  -2.5253,  -6.4886,  13.6497],\n",
              "         [-13.8412,   0.4857,   3.5472,   1.6711,   8.3584],\n",
              "         [  5.2161,   4.3817,  -0.6309,  -3.3748,   9.5136],\n",
              "         [  2.6175,  -3.8543, -11.0960,   0.2316,   5.0176]],\n",
              "\n",
              "        [[-10.2110,   1.6841,  -4.9994,   2.7654,  15.3124],\n",
              "         [ -1.6696,   4.3291,  -7.8428,  -2.3466,   1.8950],\n",
              "         [  3.2035,   4.5864,  -5.8894,   8.6451,  12.5560],\n",
              "         [ -9.7150,   3.6997,  -7.2993,   7.6571, -12.6875],\n",
              "         [ -0.3818, -24.1317,   5.5952,   1.5995,   3.9394]],\n",
              "\n",
              "        [[ 10.9530,   5.2465,   9.9187,  -2.5286,   2.2908],\n",
              "         [ 15.3642,   0.4163,  -3.3867,  14.6251,   0.6258],\n",
              "         [ -6.4831,  -2.0004,   3.6250, -10.1800,   1.4576],\n",
              "         [ -0.8054,  12.9416, -13.3502,  -1.9531,  -3.4387],\n",
              "         [  5.9473,  -0.0591,   4.9450,   3.3467,   9.6258]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(queries, keys)*(torch.sqrt(torch.tensor(keys.size(1))))**-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShQb0nMb-I5n",
        "outputId": "eaf3c1ab-a25b-4dce-c37e-741410dffa6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1106,  0.3747,  0.2776,  0.2249,  0.3440],\n",
              "         [ 0.6151, -0.1787, -0.1067, -0.2742,  0.5768],\n",
              "         [-0.5849,  0.0205,  0.1499,  0.0706,  0.3532],\n",
              "         [ 0.2204,  0.1852, -0.0267, -0.1426,  0.4020],\n",
              "         [ 0.1106, -0.1629, -0.4689,  0.0098,  0.2120]],\n",
              "\n",
              "        [[-0.4315,  0.0712, -0.2113,  0.1169,  0.6471],\n",
              "         [-0.0706,  0.1829, -0.3314, -0.0992,  0.0801],\n",
              "         [ 0.1354,  0.1938, -0.2489,  0.3653,  0.5306],\n",
              "         [-0.4105,  0.1563, -0.3085,  0.3236, -0.5361],\n",
              "         [-0.0161, -1.0198,  0.2364,  0.0676,  0.1665]],\n",
              "\n",
              "        [[ 0.4628,  0.2217,  0.4191, -0.1069,  0.0968],\n",
              "         [ 0.6493,  0.0176, -0.1431,  0.6180,  0.0264],\n",
              "         [-0.2740, -0.0845,  0.1532, -0.4302,  0.0616],\n",
              "         [-0.0340,  0.5469, -0.5641, -0.0825, -0.1453],\n",
              "         [ 0.2513, -0.0025,  0.2090,  0.1414,  0.4068]]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attentions = torch.matmul(queries, keys)*(torch.sqrt(torch.tensor(keys.size(1))))**-1"
      ],
      "metadata": {
        "id": "82my6GrK-jLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attentions.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9KT3vjK-jO0",
        "outputId": "c77d8dd8-eb88-4fa5-8666-e4aa5628a2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(attentions, values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC07bP-G-I8W",
        "outputId": "d48b6fad-3a0c-46c4-938d-850a63c6e946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3970,  0.0622,  0.4446,  ...,  0.1658, -0.1390, -0.3943],\n",
              "         [-0.4759, -1.0286,  0.0432,  ..., -0.3399, -0.5756, -0.3593],\n",
              "         [ 0.1316, -0.5678,  0.2755,  ..., -0.2129, -0.2254, -0.0814],\n",
              "         [-0.3659, -0.4534,  0.0581,  ..., -0.0093, -0.4205, -0.5891],\n",
              "         [ 0.1767, -0.5330, -0.5329,  ...,  0.2687, -0.6386, -0.4443]],\n",
              "\n",
              "        [[-0.9429,  0.4377, -0.5721,  ...,  0.4676,  0.0925, -0.7004],\n",
              "         [-0.5914,  0.1866, -0.3237,  ...,  0.1362, -0.0020, -0.3840],\n",
              "         [-0.5352,  0.3863, -0.3279,  ...,  0.2841, -0.3369, -1.1716],\n",
              "         [ 0.0963,  0.3325,  0.0582,  ...,  0.9236,  0.1016, -0.1899],\n",
              "         [ 0.7588, -0.6284,  0.0349,  ...,  0.0626,  0.0272,  1.0723]],\n",
              "\n",
              "        [[-0.1058, -0.7051,  0.3918,  ..., -0.5771,  0.6012, -0.5737],\n",
              "         [-0.1330, -0.5764, -0.1608,  ..., -0.5232, -0.0273,  0.4008],\n",
              "         [ 0.0018,  0.1371,  0.2604,  ...,  0.1715, -0.0073, -0.3464],\n",
              "         [ 0.4207,  0.5730, -0.6647,  ...,  0.9251, -0.3237,  0.2907],\n",
              "         [-0.2142, -0.6821,  0.3936,  ..., -0.4122,  0.2663, -0.2288]]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Dq02Eolqy0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijV-wtnJrINx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sq0Gagj5rIQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0yEN-1Tqy3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Linear(768, 560)\n",
        "print(m.weight.size())\n",
        "input = torch.randn(3,5, 768)\n",
        "output = m(input)\n",
        "print(output.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtsh9QEPug6F",
        "outputId": "5e65206d-44a8-453d-8a0d-5fa6e23967a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([560, 768])\n",
            "torch.Size([3, 5, 560])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JX4KI7Kug8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_layer  = embedding()"
      ],
      "metadata": {
        "id": "z79AK4KdyZuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = torch.randint(1,101,size=(3,10))"
      ],
      "metadata": {
        "id": "HeQmh61EeUPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjkHWWvbea79",
        "outputId": "c9ac83f5-1dc1-440b-806c-ef04ad22fb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = embed_layer(encodings)"
      ],
      "metadata": {
        "id": "zW_N4gmvz5hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxfceibUz5mo",
        "outputId": "f93814ff-f79e-4996-b5da-f54ab59cdd0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZ1Ml5JZz5pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rough\n",
        "\n",
        "print(torch.randint(0,101,size=(10,), dtype=torch.float32))\n",
        "# print(torch.randint(0,101,size=(1,10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzV6-KQBz5r5",
        "outputId": "3328f786-6c8c-461e-b230-a664189efba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([75., 71., 77., 20., 78., 93., 26.,  8., 44., 77.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Linear(10, 5)(torch.randint(1,101,size=(10,), dtype=torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWXtvORwB3A-",
        "outputId": "42088195-890f-460e-cc7d-dcc900e8cb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-21.6303,  10.7729,  40.9039, -22.2035, -21.5263],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = torch.randint(1,101,size=(3,5), dtype=torch.float32)\n",
        "print(encodings)\n",
        "print(encodings.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAlGVDZZDSgw",
        "outputId": "231a3db4-d71d-443c-cd73-dfe87c9e1bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[64., 76., 37., 27., 20.],\n",
            "        [71., 84.,  4., 94., 42.],\n",
            "        [79., 27., 72.,  3., 42.]])\n",
            "torch.Size([3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = nn.Linear(5, 10)(encodings)\n",
        "print(res.shape)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45VsDjivEpDj",
        "outputId": "b063fe2e-761e-4b70-f0b2-547e1d7b3f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10])\n",
            "tensor([[-21.5715,  20.1209,  -0.4824,  14.3352,  18.1300,  -1.5594, -16.9697,\n",
            "         -16.9604, -38.5803,  59.1881],\n",
            "        [-20.9963,  -7.9470,   5.9263,  15.1599,  23.3282,  17.7045,  13.4380,\n",
            "          18.2586, -58.1793,  56.8789],\n",
            "        [-13.3298,  20.9227,   5.1337,   9.4617,  41.7800,  10.1199,  -9.5355,\n",
            "          -3.4605, -31.0516,  62.9349]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=100, embedding_dim=30, padding_idx=9)"
      ],
      "metadata": {
        "id": "abrBBxMIE8cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in embedding_layer.parameters():\n",
        "  print(i.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHKOEnHjNlUq",
        "outputId": "25580222-7966-49e0-cefe-c9d2127160b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer.weight.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NdCv7qmNVCb",
        "outputId": "e3cde364-a271-4ced-e79a-df630b66d5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encodings = torch.randint(1,101,size = (10,))\n",
        "print(encodings)\n",
        "embedded = embedding_layer(encodings)\n",
        "# print(embedded)\n",
        "print(embedded.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_H_EXNAJjL7",
        "outputId": "5a6e5283-7a0c-41ca-b48e-8577473d11dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([46, 28, 55, 48, 37,  9, 51, 57, 40,  7])\n",
            "torch.Size([10, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(0,101,size=(3,5,100)).size(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWYReglvJ2OY",
        "outputId": "c57f9148-40f5-4e5b-cb8c-eee68bc11935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.arange(5)  + torch.randint(1,100,size=(2,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhMzi95xUlxu",
        "outputId": "ccb8cd48-d857-4c74-92c6-489d42ac4619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 22, 89, 17, 94],\n",
              "        [68, 10, 85, 29, 46]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.arange(5).unsqueeze(0)  + torch.randint(1,100,size=(2,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzb4c8QfUo-2",
        "outputId": "8427da80-c883-4e34-e604-c5afe84bc0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[99, 13, 57, 80, 11],\n",
              "        [32, 94, 38, 33, 23]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yS0Tb2NbByX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}